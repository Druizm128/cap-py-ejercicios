{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bosques: Error OOB e importancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error OOB\n",
    "\n",
    "Usamos los datos de seguros de Caravan. Por defecto, la evaluación de OOB es sobre el porcentaje de correctos, lo que en general no es muy útil. Por ejemplo para el problema de seguros de Caravan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# preprocesar\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "caravan = pd.read_csv('../datos/caravan-insurance-challenge.csv')\n",
    "columnas = caravan.columns[2:86]\n",
    "print(columnas)\n",
    "def preprocesar_caravan(datos, tipo, columnas):\n",
    "    # filtrar tipo\n",
    "    datos_p = datos[datos[\"ORIGIN\"] == tipo].copy()\n",
    "    # variable respuesta\n",
    "    y = datos_p[\"CARAVAN\"].values\n",
    "    datos_p = datos_p[columnas]\n",
    "    datos_tipo = pd.get_dummies(datos_p.MOSHOOFD, prefix=\"MOSHOODFD_\", drop_first = True)\n",
    "    datos_p = datos_p.drop(columns = [\"MOSHOOFD\"])\n",
    "    datos_p = pd.concat([datos_tipo, datos_p], axis = 1, sort=False)\n",
    "    columnas_x = datos_p.columns\n",
    "    #datos_origen = datos[datos[\"ORIGIN\"] == tipo].drop(columns = [\"ORIGIN\"])\n",
    "    X = datos_p.values\n",
    "    return X, y, columnas_x\n",
    "X_ent, y_ent, columnas_x = preprocesar_caravan(caravan, \"train\", columnas)\n",
    "X_pr, y_pr, _ = preprocesar_caravan(caravan, \"test\", columnas)\n",
    "print(X_ent.shape)\n",
    "np.unique(y_ent, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1500, max_features = 60, \n",
    "                            min_samples_leaf=100, oob_score = True,\n",
    "                           random_state = 10012)\n",
    "ajuste = rf.fit(X_ent, y_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ajuste.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque esta es un estimación *honesta* del error, **en general, el oob score calculado como porcentaje de correctos no es muy útil**. Solo usa corte en 0.5 y da el porcentaje de correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancia de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, sklearn usa importancia basada en gini, no la importancia de permutaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancias = ajuste.feature_importances_\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.DataFrame({\"variable\":columnas_x, \"importancia\":importancias}). \\\n",
    "    sort_values(by = \"importancia\", ascending = False).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPERSAUT: Contribution car policies\n",
    "PBRAND: Contribution fire policies \n",
    "MOPLLAAG: Lower level education\n",
    "APERSAUT: Number of car policies\n",
    "MKOOPKLA: Purchasing power class\n",
    "MOPLHOOG: High level education\n",
    "MBERMIDD: Middle management\n",
    "MINKGEM: Average income\n",
    "MINKM30: Income < 30.000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular importancia de variables usando el método de permutaciones (ojo: a partir de sklearn 0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "# si tarda mucho, podemos tomar una muestra de los datos o reducir el número de repeticiones\n",
    "r = permutation_importance(ajuste, X_ent[1:1000,:], y_ent[1:1000],\n",
    "                           n_repeats=5,\n",
    "                           random_state=0, scoring = \"roc_auc\")\n",
    "importancias_df = pd.DataFrame({\"variable\":columnas_x, \n",
    "                                \"importancia\":r.importances_mean, \n",
    "                                \"de\":r.importances_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancias_df[\"rankeo\"] = df[\"importancia\"].rank()\n",
    "importancias_df[\"imp_min\"] = df[\"importancia\"] - df[\"de\"]\n",
    "importancias_df[\"imp_max\"] = df[\"importancia\"] + df[\"de\"]\n",
    "importancias_df.sort_values(by = \"importancia\", ascending = False).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(importancias_df, aes(\"rankeo\", \"importancia\", ymin=\"imp_min\", ymax=\"imp_max\"))  \n",
    "  + geom_point() + geom_linerange())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
