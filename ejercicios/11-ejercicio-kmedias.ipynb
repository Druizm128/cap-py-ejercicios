{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentación con kmedias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos datos tomados del proyecto de kaggle *Credit Card Dataset for Clustering*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import numpy as np\n",
    "# leer datos \n",
    "general = pd.read_csv(\"../datos/CC-GENERAL.csv\")\n",
    "general.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos tomados de [kaggle](https://www.kaggle.com/arjunbhasin2013/ccdata). Las variables ya tienen algo de procesamiento previo. Podemos crear también nuevas variables que consideremos puedan ser informativas para hacer los segmentos.\n",
    "\n",
    "- CUST_ID : Identification of Credit Card holder (Categorical) \n",
    "- BALANCE : Balance amount left in their account to make purchases  \n",
    "- BALANCE_FREQUENCY : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated) \n",
    "- PURCHASES : Amount of purchases made from account \n",
    "- ONEOFF_PURCHASES : Maximum purchase amount done in one-go\n",
    "- INSTALLMENTS_PURCHASES : Amount of purchase done in installment \n",
    "- CASH_ADVANCE : Cash in advance given by the user \n",
    "- PURCHASES_FREQUENCY : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased) \n",
    "- ONEOFFPURCHASESFREQUENCY : How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased) \n",
    "- PURCHASESINSTALLMENTSFREQUENCY : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n",
    "- CASHADVANCEFREQUENCY : How frequently the cash in advance being paid \n",
    "- CASHADVANCETRX : Number of Transactions made with \"Cash in Advanced\" \n",
    "- PURCHASES_TRX : Numbe of purchase transactions made \n",
    "- CREDIT_LIMIT : Limit of Credit Card for user \n",
    "- PAYMENTS : Amount of Payment done by user \n",
    "- MINIMUM_PAYMENTS : Minimum amount of payments made by user \n",
    "- PRCFULLPAYMENT : Percent of full payment paid by user \n",
    "- TENURE : Tenure of credit card service for user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general.hist(figsize=(20, 20), bins = 50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ponemos en minúsculas las variables y calculamos resúmenes:\n",
    "general.columns = [x.lower() for x in general.columns.tolist()]\n",
    "general.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faltantes\n",
    "general.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(general[\"minimum_payments\"].isnull(), general[\"payments\"] > 0))\n",
    "# rellenar con 0 en minimum payments\n",
    "general['minimum_payments'].fillna(value = 0, inplace = True)\n",
    "# eliminar caso sin limite de cŕedito\n",
    "general.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos presentan asimetría y colas largas. Puede ser una buena idea transformar a logaritmo las variables positivas. Esto implica que nos interesan diferencias entre los casos **multiplicativas** en lugar de **aditivas**, que es más apropiado aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_pos = [\"balance\", \"purchases\", \"oneoff_purchases\", \"installments_purchases\", \"cash_advance\", \"cash_advance_trx\",\n",
    "          \"purchases_trx\", \"credit_limit\", \"payments\", \"minimum_payments\"]\n",
    "general_trans = general.copy()\n",
    "for var in vars_pos:\n",
    "    general_trans[var + \"_log\"] = np.log10(1 + general_trans[var])\n",
    "general_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionar variables para segmentar:\n",
    "vars_segmentos = [\"purchases_log\", \"oneoff_purchases_log\", \"installments_purchases_log\", \"cash_advance_log\", \n",
    "                  \"credit_limit_log\", \"payments_log\", \"minimum_payments_log\", \"balance_frequency\", \"purchases_frequency\", \n",
    "                  \"oneoff_purchases_frequency\", \"purchases_installments_frequency\", \"prc_full_payment\"]\n",
    "general_s = general_trans[vars_segmentos]\n",
    "general_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarizamos, pues las variables están en distintas escalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "x_escalada = std_scaler.fit_transform(general_s)\n",
    "general_esc = pd.DataFrame(x_escalada)\n",
    "general_esc.columns = general_s.columns\n",
    "general_esc.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segmentación por k-medias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos k-medias para construir varias soluciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# ajustar semilla para que sea reproducible\n",
    "np.random.seed(211)\n",
    "inercia = []\n",
    "num_clusters = range(1, 15)\n",
    "for i in num_clusters:\n",
    "    agrupador = KMeans(# sustituye tu código aquí)\n",
    "    kmedias = agrupador.fit(#sustituye los datos)\n",
    "    inercia.append(kmedias.inertia_)\n",
    "\n",
    "# plot\n",
    "inercia_df = pd.DataFrame({\"inercia\":inercia, \"num_clusters\":num_clusters})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inercia_df\n",
    "# haz gráfica de codo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**: Hay varias soluciones que podemos probar. ¿Qué indica la gráfica de codo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agrupar y perfilar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la segmentación y vemos cuántos clientes caen en cada grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupador = KMeans(# rellena tu código)\n",
    "agrupador_ajustado = agrupador.fit(general_esc)\n",
    "grupos = agrupador_ajustado.predict(general_esc)\n",
    "# calcula tamaño de cada grupo en crudo y porcentajes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checa convergencia de solución (si obtienes un valor igual a max_iter, puedes iterar más veces):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupador_ajustado.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a perfilar en las variables que usamos para segmentar, que están estandarizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfilar(general_esc, grupos, tipo = \"aditivo\"):\n",
    "    ### producir perfiles aditivos o multiplicativos según grupos\n",
    "    # convertimos a categoría\n",
    "    datos = general_esc.copy()\n",
    "    datos[\"grupo\"] = pd.Series(grupos).astype(\"category\")\n",
    "    # calculamos medias por grupo de las variables\n",
    "    agregados = datos.groupby(\"grupo\").mean()\n",
    "    # pivoteamos las variables a forma larga\n",
    "    agregados_larga = agregados.reset_index() \\\n",
    "        .melt(id_vars = [\"grupo\"])\n",
    "    # ahora calculamos medias totales a lo largo de grupos\n",
    "    medias = agregados_larga.drop(columns=[\"grupo\"]).groupby(\"variable\").mean() \\\n",
    "        .rename(columns = {\"value\":\"media\"})\n",
    "    # en estas líneas tomamos las medias por grupo y les agregamos\n",
    "    # la medias a total:\n",
    "    variable_cat = pd.Categorical(agregados_larga['variable'], \n",
    "        categories=agregados.columns.tolist())\n",
    "    agregados_larga = agregados_larga.assign(variable_cat = variable_cat). \\\n",
    "        merge(medias, on = \"variable\", how = \"left\")\n",
    "    # calculamos el perfil (diferencia vs media)\n",
    "    if tipo==\"aditivo\":\n",
    "        agregados_larga[\"perfil\"] = agregados_larga[\"value\"] - agregados_larga[\"media\"]\n",
    "    else:\n",
    "        agregados_larga[\"perfil\"] = 100 * (agregados_larga[\"value\"] / agregados_larga[\"media\"] - 1.0)\n",
    "    return agregados_larga\n",
    "\n",
    "agregados_larga = perfilar(general_esc, grupos)\n",
    "agregados_larga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoteamos los grupos para obtener una tabla más legible\n",
    "agregados_larga[['grupo', 'variable_cat', 'value']]. \\\n",
    "    pivot(columns = 'grupo', values='value', index = \"variable_cat\").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y usamos formato condicional para leer más facilmente\n",
    "def color_negative_red(val):\n",
    "    color = 'red' if val < -0.3 else 'black' if val > 0.3 else 'gray'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "def tabla_perfiles(agregados_larga, columna, renglon):\n",
    "    resumen_perfil = agregados_larga[['grupo', 'variable_cat', 'perfil']]. \\\n",
    "        pivot(columns='grupo', values='perfil', index=\"variable_cat\").round(2). \\\n",
    "        sort_values(by=renglon, axis=1). \\\n",
    "        sort_values(by=columna, axis=0)\n",
    "    return resumen_perfil.style.applymap(color_negative_red)\n",
    "\n",
    "tabla_perfiles(agregados_larga, columna = 2, renglon = 'purchases_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son perfiles aditivos pero en escala logarítmica estandarizada. Nos dan una idea, pero pueden ser difíciles de interpetar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de permutaciones (optativo pero útil)\n",
    "\n",
    "Para entender qué tan grandes son estas diferencias, podemos hacer una prueba de permutaciones. Permutamos los grupos y comparamos la variación contra la observada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregados_larga_perm = perfilar(general_esc, grupos[np.random.permutation(grupos.size)])\n",
    "tabla_perfiles(agregados_larga_perm, columna = 2, renglon = 'purchases_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta tabla indica que típicamente podemos considerar diferencias de alrededor de +/-0.10 son producidas por la agrupación que construimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interpretación y nombres de grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perfilar **en las variables originales** que usamos para interpretar y nombrar grupos, pero usamos **diferencias multiplicativas**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_vars = list(map(lambda x: x.replace('_log', ''), vars_segmentos))\n",
    "print(general_vars)\n",
    "agregados_larga_m = perfilar(general.loc[:, general_vars], grupos, tipo = \"mult\")\n",
    "with pd.option_context('display.precision', 3):\n",
    "    tab = tabla_perfiles(agregados_larga_m.round(0), columna = 2, renglon = 'purchases')\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos empezar a nombrar grupos. ¿Qué mejores nombres propondrías?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres = # rellena tu código con nombres apropiados {2:'a', 3:'b', 4:'c', 0:'d', 1:'f'}\n",
    "grupos_nombre = pd.Series(grupos).replace(nombres)\n",
    "agregados_larga_m['grupo'].replace(nombres, inplace = True)\n",
    "with pd.option_context('display.precision', 3):\n",
    "    tab = tabla_perfiles(agregados_larga_m.round(0), \n",
    "                         columna = 'a', renglon = 'purchases')\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**: considerarías que algunos grupos son muy similares y valdría la pena usar una solución de menos grupos. ¿Cómo se ve una solución de 4 o 6 grupos?\n",
    "\n",
    "**Ejercicio**: repite con otro número de grupos, y considera ventajas y desventajas en cuanto a la interpretación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfilamiento en variables suplementarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora perfilamos usando otras variables que no usamos en la segmentación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suplementarias = ['balance', 'tenure']\n",
    "agregados_larga_m = perfilar(general.loc[:, suplementarias], grupos_nombre, tipo = \"mult\")\n",
    "with pd.option_context('display.precision', 5):\n",
    "    tab = tabla_perfiles(agregados_larga_m.round(2), columna = \"a\", renglon = 'tenure')\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_n = grupos_nombre.value_counts()\n",
    "usuarios_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_pct = 100*usuarios_n/sum(usuarios_n)\n",
    "usuarios_pct.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este resultado no es muy útil"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
