{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio árboles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio construiremos algunos árboles de clasificación y veremos cómo seleccionar hiperparámetros para afinar medidas de desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos\n",
    "\n",
    "Usaremos los datos de ventas de seguros de *Caravan*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "caravan = pd.read_csv('../datos/caravan-insurance-challenge.csv')\n",
    "columnas = caravan.columns[2:86]\n",
    "print(columnas)\n",
    "def preprocesar_caravan(datos, tipo, columnas):\n",
    "    # filtrar tipo\n",
    "    datos_p = datos[datos[\"ORIGIN\"] == tipo].copy()\n",
    "    # variable respuesta\n",
    "    y = datos_p[\"CARAVAN\"].values\n",
    "    datos_p = datos_p[columnas]\n",
    "    datos_tipo = pd.get_dummies(datos_p.MOSHOOFD, prefix=\"MOSHOODFD_\", drop_first = True)\n",
    "    datos_p = datos_p.drop(columns = [\"MOSHOOFD\"])\n",
    "    datos_p = pd.concat([datos_tipo, datos_p], axis = 1, sort=False)\n",
    "    columnas_x = datos_p.columns\n",
    "    #datos_origen = datos[datos[\"ORIGIN\"] == tipo].drop(columns = [\"ORIGIN\"])\n",
    "    X = datos_p.values\n",
    "    return X, y, columnas_x\n",
    "X_ent, y_ent, columnas_x = preprocesar_caravan(caravan, \"train\", columnas)\n",
    "print(X_ent.shape)\n",
    "print(columnas_x)\n",
    "np.unique(y_ent, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "MOSTYPE: Customer Subtype; see L0 MAANTHUI: Number of houses 1 - 10 MGEMOMV: Avg size household 1 - 6 MGEMLEEF: Avg age; see L1 MOSHOOFD: Customer main type; see L2\n",
    "\n",
    "MGODRK: Roman catholic MGODPR: Protestant … MGODOV: Other religion MGODGE: No religion MRELGE: Married MRELSA: Living together MRELOV: Other relation MFALLEEN: Singles MFGEKIND: Household without children MFWEKIND: Household with children MOPLHOOG: High level education MOPLMIDD: Medium level education MOPLLAAG: Lower level education MBERHOOG: High status MBERZELF: Entrepreneur MBERBOER: Farmer MBERMIDD: Middle management MBERARBG: Skilled labourers MBERARBO: Unskilled labourers MSKA: Social class A MSKB1: Social class B1 MSKB2: Social class B2 MSKC: Social class C MSKD: Social class D MHHUUR: Rented house MHKOOP: Home owners MAUT1: 1 car MAUT2: 2 cars MAUT0: No car MZFONDS: National Health Service MZPART: Private health insurance MINKM30: Income < 30.000 MINK3045: Income 30-45.000 MINK4575: Income 45-75.000 MINK7512: Income 75-122.000 MINK123M: Income >123.000 MINKGEM: Average income MKOOPKLA: Purchasing power class\n",
    "\n",
    "PWAPART: Contribution private third party insurance PWABEDR: Contribution third party insurance (firms) … PWALAND: Contribution third party insurane (agriculture) PPERSAUT: Contribution car policies PBESAUT: Contribution delivery van policies PMOTSCO: Contribution motorcycle/scooter policies PVRAAUT: Contribution lorry policies PAANHANG: Contribution trailer policies PTRACTOR: Contribution tractor policies PWERKT: Contribution agricultural machines policies PBROM: Contribution moped policies PLEVEN: Contribution life insurances PPERSONG: Contribution private accident insurance policies PGEZONG: Contribution family accidents insurance policies PWAOREG: Contribution disability insurance policies PBRAND: Contribution fire policies PZEILPL: Contribution surfboard policies PPLEZIER: Contribution boat policies PFIETS: Contribution bicycle policies PINBOED: Contribution property insurance policies PBYSTAND: Contribution social security insurance policies AWAPART: Number of private third party insurance 1 - 12 AWABEDR: Number of third party insurance (firms) … AWALAND: Number of third party insurance (agriculture) APERSAUT: Number of car policies ABESAUT: Number of delivery van policies AMOTSCO: Number of motorcycle/scooter policies AVRAAUT: Number of lorry policies AAANHANG: Number of trailer policies ATRACTOR: Number of tractor policies AWERKT: Number of agricultural machines policies ABROM: Number of moped policies ALEVEN: Number of life insurances APERSONG: Number of private accident insurance policies AGEZONG: Number of family accidents insurance policies AWAOREG: Number of disability insurance policies ABRAND: Number of fire policies AZEILPL: Number of surfboard policies APLEZIER: Number of boat policies AFIETS: Number of bicycle policies AINBOED: Number of property insurance policies ABYSTAND: Number of social security insurance policies CARAVAN: Number of mobile home policies 0 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustando un aŕbol de clasificación\n",
    "\n",
    "Ajusta un árbol relativamente chico. Podemos controlar con mínimo número de muestras por nodo, mínimo para por nodo para considerar dividirlo, máxima profundidad y mínimo decrecimiento de impureza para decidir cortar, \n",
    "por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "arbol = tree.DecisionTreeClassifier(min_samples_split = 200,\n",
    "                                  min_samples_leaf = 100, \n",
    "                                  max_depth = 4,\n",
    "                                  criterion = \"entropy\",\n",
    "                                  min_impurity_decrease = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_caravan_ajuste = arbol.fit(X_ent, y_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar árbol\n",
    "variables_nombres = columnas\n",
    "fig, ax = plt.subplots(1, 1, figsize = (4,4), dpi = 300)\n",
    "ax.set_title('Árbol completo')\n",
    "anotacion = tree.plot_tree(arbol_caravan_ajuste, ax = ax,\n",
    "                           feature_names = columnas_x,\n",
    "                           filled = True, \n",
    "                           proportion = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = tree.DecisionTreeClassifier(min_samples_split = 100,\n",
    "                                  min_samples_leaf = 50, \n",
    "                                  max_depth = 5)\n",
    "arbol_caravan_ajuste = arbol.fit(X_ent, y_ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación y comparación con regresión logística\n",
    "\n",
    "\n",
    "Comparamos con regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador = StandardScaler()\n",
    "escalador_ajustado = escalador.fit(X_ent)\n",
    "X_ent_esc = escalador_ajustado.transform(X_ent)\n",
    "reg_caravan = LogisticRegression(solver='newton-cg', penalty=\"none\")\n",
    "reg_caravan_ajuste = reg_caravan.fit(X_ent_esc, y_ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pr, y_pr, _ = preprocesar_caravan(caravan, \"test\", columnas)\n",
    "X_pr_esc = escalador_ajustado.transform(X_pr)\n",
    "# calcular probabilidades\n",
    "probas_reg  = reg_caravan_ajuste.predict_proba(X_pr_esc)\n",
    "probas_arbol = arbol_caravan_ajuste.predict_proba(X_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Evaluamos los dos modelos en muestra de prueba. Primero el modelo de regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "tfp, tvp, cortes = roc_curve(y_pr, probas_reg[:,1])\n",
    "datos_roc = pd.DataFrame({\"tfp\":tfp, \"tvp\":tvp, \"corte\":cortes})\n",
    "datos_roc[\"tipo\"] = \"reg logistica\" \n",
    "print(\"AUC prueba reg:\", roc_auc_score(y_pr, probas_reg[:,1]).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora el árbol que ajustamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp, tvp, cortes = roc_curve(y_pr, probas_arbol[:,1])\n",
    "datos_roc_2 = pd.DataFrame({\"tfp\":tfp, \"tvp\":tvp, \"corte\":cortes})\n",
    "datos_roc_2[\"tipo\"] = \"arbol_chico\"\n",
    "print(\"AUC prueba árbol:\", roc_auc_score(y_pr, probas_arbol[:,1]).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_roc = pd.concat([datos_roc, datos_roc_2])\n",
    "(ggplot(datos_roc, aes(\"tfp\", \"tvp\", group=\"tipo\", colour=\"tipo\")) \n",
    "  + geom_step(size=1.5)\n",
    "  + geom_abline(slope=1, intercept=0)\n",
    "  + xlab(\"Tasa de falsos positivos\") + ylab(\"Sensibilidad\")\n",
    "  + labs(title =\"Curva ROC prueba\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque en entrenamiento la situación se ve diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicciones\n",
    "probas_reg  = reg_caravan_ajuste.predict_proba(X_ent_esc)\n",
    "probas_arbol = arbol_caravan_ajuste.predict_proba(X_ent)\n",
    "# reg\n",
    "tfp, tvp, cortes = roc_curve(y_ent, probas_reg[:,1])\n",
    "datos_roc = pd.DataFrame({\"tfp\":tfp, \"tvp\":tvp, \"corte\":cortes})\n",
    "datos_roc[\"tipo\"] = \"reg logistica\" \n",
    "# arbol\n",
    "tfp, tvp, cortes = roc_curve(y_ent, probas_arbol[:,1])\n",
    "# grafica\n",
    "print(\"AUC entrena árbol:\", roc_auc_score(y_ent, probas_arbol[:,1]).round(3))\n",
    "print(\"AUC entrena regresión:\", roc_auc_score(y_ent, probas_reg[:,1]).round(3))\n",
    "\n",
    "datos_roc_2 = pd.DataFrame({\"tfp\":tfp, \"tvp\":tvp, \"corte\":cortes})\n",
    "datos_roc_2[\"tipo\"] = \"arbol_chico\"\n",
    "datos_roc = pd.concat([datos_roc, datos_roc_2])\n",
    "(ggplot(datos_roc, aes(\"tfp\", \"tvp\", group=\"tipo\", colour=\"tipo\")) \n",
    "  + geom_step(size=1.5)\n",
    "  + geom_abline(slope=1, intercept=0)\n",
    "  + xlab(\"Tasa de falsos positivos\") + ylab(\"Sensibilidad\")\n",
    "  + labs(title = \"Curva ROC entrenamiento\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**: ¿cuál es la razón de este comportamiento malo del árbol en la muestra de prueba?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afinación de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, \\\n",
    "    auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix, \\\n",
    "    average_precision_score\n",
    "\n",
    "hiperparams_rejilla = {\n",
    "    'min_samples_split': [10, 50, 100], \n",
    "    'min_samples_leaf': [5, 10, 50],\n",
    "    'max_depth' : [2, 4, 6, 8, 10],\n",
    "    'min_impurity_decrease' : [1e-8, 1e-6, 1e-4]\n",
    "}\n",
    "\n",
    "calificadores = {\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'auc': make_scorer(roc_auc_score, needs_proba=True),\n",
    "    'precision_promedio': make_scorer(average_precision_score, needs_proba = True)\n",
    "}\n",
    "\n",
    "\n",
    "arbol = tree.DecisionTreeClassifier()\n",
    "cortes_val = StratifiedKFold(n_splits=10, random_state=2334)\n",
    "# busqueda\n",
    "busqueda_grid = GridSearchCV(arbol, hiperparams_rejilla, \n",
    "                            scoring=calificadores, \n",
    "                            refit=\"auc\", \n",
    "                            return_train_score = True,\n",
    "                            cv=cortes_val, n_jobs = -1)\n",
    "busqueda_grid = busqueda_grid.fit(X_ent, y_ent)\n",
    "print('Mejores parámetros para {}'.format(\"auc\"))\n",
    "print(busqueda_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos resultados\n",
    "resultados = pd.DataFrame(busqueda_grid.cv_results_)\n",
    "resultados\n",
    "resultados = resultados.sort_values(by='mean_test_auc', ascending=False)\n",
    "resultados.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[[\"param_max_depth\", \"param_min_impurity_decrease\", \"param_min_samples_leaf\", \n",
    "        \"param_min_samples_split\", \"params\", \"mean_test_auc\", \"std_test_auc\", \"mean_train_auc\"]].round(3).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_arbol = busqueda_grid.predict_proba(X_pr)\n",
    "print(\"AUC:\", roc_auc_score(y_pr, probas_arbol[:,1]).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos afinar también la regularización en regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparams_rejilla = {\n",
    "    'C': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "calificadores = {\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'auc': make_scorer(roc_auc_score, needs_proba=True),\n",
    "    'precision_promedio': make_scorer(average_precision_score, needs_proba = True)\n",
    "}\n",
    "\n",
    "\n",
    "reg_log = LogisticRegression(solver = \"newton-cg\")\n",
    "# busqueda\n",
    "busqueda_grid = GridSearchCV(reg_log, hiperparams_rejilla, \n",
    "                               scoring=calificadores, \n",
    "                               refit=\"auc\", \n",
    "                               cv=cortes_val, n_jobs = -1)\n",
    "busqueda_grid = busqueda_grid.fit(X_ent_esc, y_ent)\n",
    "print('Mejores parámetros para {}'.format(\"auc\"))\n",
    "print(busqueda_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_reg = busqueda_grid.predict_proba(X_pr_esc)\n",
    "print(\"AUC:\", roc_auc_score(y_pr, probas_reg[:,1]).round(2))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
